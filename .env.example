# Tabula-8B Environment Configuration
# Copy this file to .env and adjust settings as needed

# Model Configuration
TABULA_MODEL_NAME=mlfoundations/tabula-8b
TABULA_CACHE_DIR=~/.cache/huggingface

# Hardware Configuration
# Options: cuda, cpu, auto
TABULA_DEVICE=auto

# Memory Optimization
# Set to true for memory-constrained environments
USE_8BIT_QUANTIZATION=false
USE_4BIT_QUANTIZATION=false

# Inference Settings
MAX_SEQUENCE_LENGTH=2048
TEMPERATURE=0.1
TOP_P=0.95

# Batch Processing
DEFAULT_BATCH_SIZE=4

# Hugging Face Hub (optional, for private models)
# HF_TOKEN=your_token_here

# Logging
LOG_LEVEL=INFO
LOG_FILE=tabula_8b.log